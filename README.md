## Overview
This repository includes an implementation of a Transformer model from scratch in Python, evaluating it on tasks such as sequence reversal, arithmetic, copying, sorting, and text generation. Task-specific hyperparameter tuning yields high accuracy on simpler tasks, with moderate success in more complex ones, illustrating the Transformerâ€™s versatility in sequence learning.
